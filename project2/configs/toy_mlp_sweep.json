{ 
  "mlp.init_lr": [
    1e-3, 1e-4, 1e-5
  ],
  "mlp.num_layers": [
    1,
    4,
    8,
    12,
    24
  ],
  "mlp.hidden_dim": [
      128, 
      256,
      512
  ],
  "mlp.use_bn": [
    true,
    false
  ],
  "main.use_data_augmentation": [
    true,
    false
  ],
  "main.batch_size": [
    512, 256, 128
  ],
  "trainer.max_epochs": [
    100, 300, 500, 1000
  ],
  "main.model_name": [
    "mlp"
  ] 

}
